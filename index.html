<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="When Would Vision-Proprioception Policies Fail in Robotic Manipulation?">
    <title>When Would Vision-Proprioception Policies Fail in Robotic Manipulation?</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1 1'><rect width='1' height='1' fill='transparent'/></svg>">
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1 1'><rect width='1' height='1' fill='transparent'/></svg>">
    <link rel="stylesheet" href="./static/css/stylesheet.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <script src="https://unpkg.com/scrollreveal@4.0.0/dist/scrollreveal.min.js"></script>
    <style>
        /* Additional styles for video section and content */
        .publication-video {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%;
            overflow: hidden;
            border-radius: 10px;
            background: #000;
            margin: 2rem 0;
        }

        .publication-video video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: contain;
        }

        .experiment-videos-grid {
            margin: 2rem 0;
        }

        .experiment-video-item {
            padding: 1rem;
            background: var(--bg-secondary);
            border-radius: 10px;
            box-shadow: var(--shadow-light);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            margin-bottom: 1.5rem;
        }

        .experiment-video-item:hover {
            transform: translateY(-5px);
            box-shadow: var(--shadow-medium);
        }

        .experiment-video-item h4 {
            font-size: 1.1rem;
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 0.5rem;
            text-align: center;
        }

        .experiment-video-item video {
            width: 100%;
            border-radius: 10px;
            display: block;
            background: #000;
            min-height: 200px;
            object-fit: contain;
        }

        .interpolation-image {
            width: 100%;
            border-radius: 10px;
            margin: 2rem 0;
            box-shadow: var(--shadow-medium);
        }

        .content-section {
            max-width: 900px;
            margin: 0 auto;
            line-height: 1.8;
            color: var(--text-secondary);
        }

        .content-section p {
            margin-bottom: 1.5rem;
        }

        .content-section h3 {
            font-size: 1.5rem;
            font-weight: 600;
            color: var(--text-primary);
            margin: 2rem 0 1rem 0;
        }

        .publication-header {
            text-align: center;
            margin-bottom: 3rem;
        }

        .publication-title {
            font-size: 2.5rem;
            font-weight: 700;
            color: var(--text-primary);
            margin-bottom: 1rem;
            line-height: 1.3;
        }

        .publication-venue {
            font-size: 1.2rem;
            color: var(--text-secondary);
            margin-bottom: 1.5rem;
        }

        .publication-authors {
            font-size: 1.1rem;
            line-height: 1.8;
            color: var(--text-secondary);
            margin-bottom: 1rem;
        }

        .publication-authors a {
            color: var(--accent-primary);
            text-decoration: none;
        }

        .publication-authors a:hover {
            text-decoration: underline;
        }

        .publication-links {
            display: flex;
            gap: 1rem;
            justify-content: center;
            flex-wrap: wrap;
            margin: 2rem 0;
        }

        .pub-link-button {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.75rem 1.5rem;
            background: var(--bg-secondary);
            color: var(--text-primary);
            text-decoration: none;
            border-radius: 0.75rem;
            font-weight: 500;
            transition: all 0.3s ease;
            border: 1px solid var(--border-primary);
            box-shadow: var(--shadow-light);
        }

        .pub-link-button:hover {
            transform: translateY(-2px);
            box-shadow: var(--shadow-medium);
            background: var(--accent-primary);
            color: white;
            border-color: var(--accent-primary);
        }

        .author-affiliation {
            font-size: 1rem;
            color: var(--text-secondary);
            margin-top: 1rem;
            line-height: 1.6;
        }

        .author-note {
            font-size: 0.9rem;
            color: var(--text-tertiary);
            margin-top: 0.5rem;
            font-style: italic;
        }

        .bibtex-section {
            background: var(--bg-secondary);
            padding: 2rem;
            border-radius: 1rem;
            margin: 2rem 0;
        }

        .bibtex-section pre {
            background: var(--bg-primary);
            padding: 1.5rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            border: 1px solid var(--border-primary);
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }

        .image-caption {
            text-align: center;
            color: var(--text-secondary);
            font-size: 0.9rem;
            margin-top: 0.5rem;
            font-style: italic;
        }

        .hero-section {
            min-height: 0;
            padding: 2rem 0 1.5rem;
        }

        #video.section {
            padding-top: 1.5rem;
        }
    </style>
</head>

<body>
    <!-- Scroll Progress Indicator -->
    <div class="scroll-indicator">
        <div class="scroll-progress" id="scrollProgress"></div>
    </div>

    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="#home" class="nav-link">Home</a>
            <a href="#video" class="nav-link">Video</a>
            <a href="#abstract" class="nav-link">Abstract</a>
            <a href="#introduction" class="nav-link">Introduction</a>
            <a href="#experiments" class="nav-link">Experiments</a>
            <a href="#conclusion" class="nav-link">Conclusion</a>
            <!-- <a href="#bibtex" class="nav-link">BibTeX</a> -->
        </div>
    </nav>

    <!-- Main Container -->
    <main class="main-container">
        <!-- Hero Section / Publication Header -->
        <section id="home" class="hero-section">
            <div class="hero-content" style="grid-template-columns: 1fr;">
                <div class="publication-header">
                    <h1 class="publication-title">When Would Vision-Proprioception Policies Fail in Robotic Manipulation?</h1>
                    <p class="publication-venue">International Conference on Learning Representations (ICLR) 2026</p>
                    <div class="publication-authors">
                        <span class="author-block">
                            <a href="https://github.com/JingxianLu/" target="_blank">Jingxian Lu</a><sup>1,*</sup>,
                        </span>
                        <span class="author-block">
                            <a href="https://xwinks.github.io/" target="_blank">Wenke Xia</a><sup>1,*</sup>,
                        </span>
                        <span class="author-block">
                            <a>Yuxuan Wu</a><sup>2</sup>,
                        </span>
                        <span class="author-block">
                            <a href="https://scholar.google.cz/citations?user=OUXS8doAAAAJ" target="_blank">Zhiwu Lu</a><sup>1</sup>,
                        </span>
                        <span class="author-block">
                            <a href="https://scholar.google.cz/citations?user=F7bvTOEAAAAJ" target="_blank">Di Hu</a><sup>1,†</sup>
                        </span>
                    </div>
                    <div class="author-affiliation">
                        <span class="author-block"><sup>1</sup>Gaoling School of Artificial Intelligence, Renmin University of China</span><br>
                        <span class="author-block"><sup>2</sup>School of Artificial Intelligence, Beihang University</span><br>
                    </div>
                    <div class="author-note">
                        <span>* Equal contribution, † Corresponding author</span>
                    </div>
                    <div class="publication-links">
                        <a href="https://openreview.net/forum?id=2RIqqNqALN&noteId=NwdhXObvoO" target="_blank" class="pub-link-button">
                            <i class="fas fa-file-pdf"></i>
                            <span>Paper</span>
                        </a>
                        <a href="https://github.com/GeWu-Lab/Gradient_Adjustment_with_Phase-guidance" target="_blank" class="pub-link-button">
                            <i class="fab fa-github"></i>
                            <span>Code</span>
                        </a>
                    </div>
                </div>
            </div>
        </section>

        <!-- Video Section -->
        <section id="video" class="section">
            <div class="section-header">
                <h2 class="section-title">Video</h2>
            </div>
            <div class="content-section">
                <div class="publication-video">
                    <video id="intro-video" autoplay controls muted playsinline>
                        <source src="./static/videos/demo.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </section>

        <!-- Abstract Section -->
        <section id="abstract" class="section">
            <div class="section-header">
                <h2 class="section-title">Abstract</h2>
            </div>
            <div class="content-section">
                <p>
                    In this work, we found that during task sub-phases that robot's motion transitions, the vision modality of the vision-proprioception policy plays a limited role. Further analysis reveals that the policy naturally gravitates toward concise proprioceptive signals that offer faster loss reduction when training, thereby dominating the optimization and suppressing the learning of the visual modality during motion-transition phases. 
                    To alleviate this, we propose the Gradient Adjustment with Phase-guidance (GAP) algorithm, leading to robust and generalizable vision-proprioception policies. 
                    The comprehensive experiments demonstrate GAP is applicable in both simulated and real-world environments, across one-arm and dual-arm setups, and compatible with both conventional and Vision-Language-Action models.
                    We believe this work can offer valuable insights into the development of vision-proprioception policies in robotic manipulation.
                </p>
            </div>
        </section>

        <!-- Introduction Section -->
        <section id="introduction" class="section">
            <div class="section-header">
                <h2 class="section-title">Introduction</h2>
            </div>
            <div class="content-section">
                <figure style="margin: 2rem 0;">
                    <img src="./static/images/teaser.svg" class="interpolation-image" alt="Generalization of vision-proprioception policies" style="width: 100%;">
                    <figcaption class="image-caption" style="text-align: left;">Figure 1: The generalization of vision-proprioception policies. (left) Vision-Proprioception policies perform 15.8% worse than Vision-only policies. (right) We explore this through intervening the task execution of vision-only policy during different periods, by switching to vision-proprioception policy. Such intervention has minimal impact during motion-consistent phases like "move forward". However, during motion-transition phases like "locate base" and "assemble them", switching leads to noticeable degradation, indicating the vision modality fails to take effect during these phases.</figcaption>
                </figure>
                <p>
                    Figure 1 (right) suggests that the vision modality of the vision-proprioception policy fails to take effect during motion-transition phases.
                    To alleviate this, we propose the Gradient Adjustment with Phase-guidance (GAP) algorithm that adaptively modulates the optimization of proprioception, enabling dynamic collaboration between vision and proprioception.
                </p>

                <figure style="margin: 2rem 0;">
                    <img src="./static/images/method.svg" class="interpolation-image" alt="The pipeline of Gradient Adjustment with Phase-guidance (GAP) algorithm." style="width: 100%;">
                    <figcaption class="image-caption" style="text-align: left;">Figure 2: The pipeline of Gradient Adjustment with Phase-guidance (GAP) algorithm.</figcaption>
                </figure>
            </div>
        </section>

        <!-- Experiments Section -->
        <section id="experiments" class="section">
            <div class="section-header">
                <h2 class="section-title">Experiments</h2>
            </div>

            <div class="content-section">        
                <p>We validate the versatility and effectiveness of our proposed GAP algorithm. The evaluations comprehensively cover a wide range of manipulation tasks, including articulated object manipulation, rotation-sensitive tasks, as well as long-horizon and contact-rich tasks.</p>

                <p>We conducted comparative analyses between our algorithm and the following baselines:</p>
                <ul>
                    <li><a href="https://arxiv.org/abs/2408.01366" target="_blank" class="link-highlight">MS-Bot</a>: this method uses state tokens with stage information to guide the dynamic collaboration of modalities within multi-modality policy.</li>
                    <li>Auxiliary Loss (Aux): following <a href="https://arxiv.org/abs/2406.10454" target="_blank" class="link-highlight">HumanPlus</a>, we use visual feature to predict the next frames as an auxiliary loss, which tries to enhance the vision modality.</li>
                    <li>Mask: to prevents the overfitting to specific modality, <a href="https://arxiv.org/abs/2410.07864" target="_blank" class="link-highlight">RDT-1B</a> randomly and independently masks each uni-modal input with a certain probability during encoding. We adapt the algorithm by masking only proprioception modality instead.</li>
                </ul>

                <div style="margin: 2rem 0;">
                    <img src="./static/images/comparative.png" class="interpolation-image" alt="Comparative Results"/>
                    <figcaption class="image-caption" style="text-align: left;">Table 1: Comparisons with other methods in both simulated and real-world environments. Average success rate and standard deviation of simulation results are calculated over 5 seeds. The vision-proprioception policies after our gradient adjustment significantly outperform other methods.</figcaption>
                </div>

                <!-- Experiment Videos Grid -->
                <div class="experiment-videos-grid">
                    <div class="video-row video-row-landscape" style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 1.5rem; margin-bottom: 1.5rem;">
                        <div class="experiment-video-item">
                            <h4>handover (4x)</h4>
                            <video autoplay controls muted playsinline style="aspect-ratio: 1248/720;">
                                <source src="./static/videos/handover4x.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="experiment-video-item">
                            <h4>put thermos into bag (4x)</h4>
                            <video autoplay controls muted playsinline style="aspect-ratio: 1248/720;">
                                <source src="./static/videos/cup2bag4x.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <div class="video-row video-row-portrait" style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 1.5rem; justify-items: center;">
                        <div class="experiment-video-item" style="max-width: 300px;">
                            <h4>press button</h4>
                            <video autoplay controls muted playsinline style="aspect-ratio: 720/1280; width: 100%; max-height: 380px; object-fit: contain;">
                                <source src="./static/videos/press_button.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="experiment-video-item" style="max-width: 300px;">
                            <h4>cube</h4>
                            <video autoplay controls muted playsinline style="aspect-ratio: 720/1280; width: 100%; max-height: 380px; object-fit: contain;">
                                <source src="./static/videos/pick_place.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="experiment-video-item" style="max-width: 300px;">
                            <h4>use rag to sweep table (4x)</h4>
                            <video autoplay controls muted playsinline style="aspect-ratio: 720/1280; width: 100%; max-height: 380px; object-fit: contain;">
                                <source src="./static/videos/rag_sweep4x.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>


            </div>
        </section>

        <!-- Conclusion Section -->
        <section id="conclusion" class="section">
            <div class="section-header">
                <h2 class="section-title">Conclusion</h2>
            </div>
            <div class="content-section">
                <p>
                    In this work, we illustrate that the vision modality of the vision-proprioception policy plays a limited role during motion-transition phases due to suppression. To alleviate this, we propose the Gradient Adjustment with Phase-guidance (GAP) algorithm, enabling dynamic collaboration between vision and proprioception within vision-proprioception policy. We believe this work can offer valuable insights into the development of vision-proprioception policies for robotic manipulation.
                </p>
            </div>
        </section>

        <!-- BibTeX Section -->
        <!-- <section id="bibtex" class="section">
            <div class="section-header">
                <h2 class="section-title">BibTeX</h2>
            </div>
            <div class="content-section">
                <div class="bibtex-section">
                    <pre><code>

                    </code></pre>1
                </div>
            </div>
        </section> -->

    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="footer-content">
            <div class="footer-left">
                <p>Updated 2024</p>
            </div>
            <div class="footer-right">
                <p>Thanks <a href="https://jonbarron.info" target="_blank">Jon Barron</a> for the original template inspiration</p>
            </div>
        </div>
    </footer>

    <!-- Scroll to Top Button -->
    <button class="scroll-top" id="scrollTop" aria-label="Scroll to top">
        <i class="fas fa-arrow-up"></i>
    </button>

    <script>
        // Smooth scrolling for navigation links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });

        // Scroll Progress Indicator
        const scrollProgress = document.getElementById('scrollProgress');
        window.addEventListener('scroll', () => {
            const scrollTop = window.pageYOffset;
            const docHeight = document.body.offsetHeight - window.innerHeight;
            const scrollPercent = (scrollTop / docHeight) * 100;
            scrollProgress.style.width = scrollPercent + '%';
        });

        // Enhanced Scroll animations with ScrollReveal
        ScrollReveal().reveal('.hero-content', { 
            duration: 1000,
            distance: '50px',
            origin: 'top',
            easing: 'cubic-bezier(0.5, 0, 0, 1)'
        });

        ScrollReveal().reveal('.publication-video', { 
            duration: 1000,
            distance: '50px',
            origin: 'bottom',
            easing: 'cubic-bezier(0.25, 0.46, 0.45, 0.94)'
        });

        ScrollReveal().reveal('.experiment-video-item', { 
            duration: 800,
            distance: '30px',
            origin: 'bottom',
            interval: 100,
            easing: 'cubic-bezier(0.25, 0.46, 0.45, 0.94)'
        });

        ScrollReveal().reveal('.interpolation-image', { 
            duration: 800,
            distance: '30px',
            origin: 'left',
            easing: 'cubic-bezier(0.25, 0.46, 0.45, 0.94)'
        });

        // Section reveal on scroll
        const sections = document.querySelectorAll('.section');
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const sectionObserver = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('revealed');
                }
            });
        }, observerOptions);

        sections.forEach(section => {
            sectionObserver.observe(section);
        });

        // Scroll to top button
        const scrollTopBtn = document.getElementById('scrollTop');
        
        window.addEventListener('scroll', () => {
            if (window.pageYOffset > 300) {
                scrollTopBtn.classList.add('show');
            } else {
                scrollTopBtn.classList.remove('show');
            }
        });

        scrollTopBtn.addEventListener('click', () => {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Active navigation highlighting
        window.addEventListener('scroll', () => {
            let current = '';
            const sections = document.querySelectorAll('section');
            
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                const sectionHeight = section.clientHeight;
                if (pageYOffset >= sectionTop - 200) {
                    current = section.getAttribute('id');
                }
            });

            document.querySelectorAll('.nav-link').forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        });

        // Add loading animation
        window.addEventListener('load', () => {
            document.body.classList.add('loaded');
        });

        // Enhanced hover effects for interactive elements
        document.querySelectorAll('.experiment-video-item').forEach(item => {
            item.addEventListener('mouseenter', function() {
                this.style.transform = 'translateY(-5px) scale(1.02)';
            });
            
            item.addEventListener('mouseleave', function() {
                this.style.transform = 'translateY(0) scale(1)';
            });
        });
    </script>
</body>
</html>
